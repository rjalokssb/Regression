{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
      ],
      "metadata": {
        "id": "gFU7bu5540t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lasso Regression is a powerful tool for performing regression analysis when there are a large number of potential predictors, and when there is a need to perform variable selection and regularization in order to prevent overfitting."
      ],
      "metadata": {
        "id": "Oh0w8dQe5cDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the main advantage of using Lasso Regression in feature selection?"
      ],
      "metadata": {
        "id": "iqt328ev40qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lasso Regression is a powerful tool for feature selection, particularly when there are a large number of potential predictors and a need to balance model interpretability with predictive performance."
      ],
      "metadata": {
        "id": "LDCXYVUR5ccK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How do you interpret the coefficients of a Lasso Regression model?"
      ],
      "metadata": {
        "id": "lX_3Fdm640nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To interpret the coefficients of a Lasso Regression model, you can use the equation generated by the model. In this equation, each predictor is multiplied by its coefficient and included in the product for that particular predictor."
      ],
      "metadata": {
        "id": "0wT681Ay5czK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
        "model's performance?"
      ],
      "metadata": {
        "id": "7MHziUTM40jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso Regression has one primary tuning parameter, called alpha (Î±), which controls the strength of the regularization penalty applied to the coefficients.\n",
        "# A higher value of alpha results in more regularization, which leads to a sparser model with fewer predictors and smaller coefficients. This can help to reduce overfitting but may also increase bias in the model. On the other hand, a lower value of alpha results in less regularization, which leads to a model with more predictors and larger coefficients. This can improve the model's fit to the data but may increase the risk of overfitting."
      ],
      "metadata": {
        "id": "f5reYkLX5dJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
      ],
      "metadata": {
        "id": "AMKSqBfy40gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yes, Lasso Regression can be used for non-linear regression problems by applying transformations to the predictor variables before fitting the model. By transforming the predictors, you can capture non-linear relationships between the predictors and the outcome variable."
      ],
      "metadata": {
        "id": "T2axbgSe5doi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What is the difference between Ridge Regression and Lasso Regression?"
      ],
      "metadata": {
        "id": "QND4vADO40c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The main difference between Ridge Regression and Lasso Regression is in the way they penalize the coefficients of the predictors.\n",
        "# Ridge Regression tends to produce models that include all predictors with smaller coefficients, while Lasso Regression tends to produce models that include only a subset of the predictors with some coefficients set to zero. "
      ],
      "metadata": {
        "id": "_tvnpiDK5eH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
      ],
      "metadata": {
        "id": "mMkA624P4z3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yes, Lasso Regression can handle multicollinearity in the input features by selecting one of the correlated features and setting the coefficients of the others to zero"
      ],
      "metadata": {
        "id": "mVEX8qt35ewD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
      ],
      "metadata": {
        "id": "oLn0CJIu5Ba3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzNf2P_s4x0X"
      },
      "outputs": [],
      "source": [
        "# The optimal value of the regularization parameter (alpha or lambda) in Lasso Regression can be chosen through a process called hyperparameter tuning. \n",
        "# grid search\n",
        "# random search\n",
        "# cross validation"
      ]
    }
  ]
}