{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?"
      ],
      "metadata": {
        "id": "TWFUURyqayTT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrpJImUDag1g"
      },
      "outputs": [],
      "source": [
        "# R-squared is a statistical measure that indicates how well the linear regression model fits the data\n",
        "# R-squared is calculated as 1 - (SSR/SST)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
      ],
      "metadata": {
        "id": "IG1H8g5ra1Im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusted R-squared is a modification of the regular R-squared value that takes into account the number of independent variables used in a linear regression model.\n",
        "# The regular R-squared value can be misleading when comparing models with different numbers of independent variables, as it tends to increase as more variables are added to the model, even if they do not improve the model's overall fit"
      ],
      "metadata": {
        "id": "Ji_EMTVZa4Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. When is it more appropriate to use adjusted R-squared?"
      ],
      "metadata": {
        "id": "QmjTM5lga43x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusted R-squared is more appropriate to use when comparing linear regression models that have different numbers of independent variables."
      ],
      "metadata": {
        "id": "3ZJf7LWHa7rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics calculated, and what do they represent?"
      ],
      "metadata": {
        "id": "Qa1Ajx9da8aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSE, MSE, MAE thes all are cost functions.\n",
        "# Root Mean Squared Error (RMSE) is the square root of the average of the squared differences between the predicted values and the actual values. RMSE is a measure of the average magnitude of the errors in the predictions of the model. The formula for RMSE is:\n",
        "# Mean Squared Error (MSE) is the average of the squared differences between the predicted values and the actual values. MSE is a measure of the average magnitude of the squared errors in the predictions of the model. The formula for MSE is:\n",
        "# Mean Absolute Error (MAE) is the average of the absolute differences between the predicted values and the actual values. MAE is a measure of the average magnitude of the errors in the predictions of the model. The formula for MAE is:\n"
      ],
      "metadata": {
        "id": "DTEW7iGza_-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in regression analysis."
      ],
      "metadata": {
        "id": "YMns816BbAtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sensitive to outliers: RMSE and MSE are more sensitive to outliers than MAE\n",
        "# RMSE, MSE is differenciable and has 1 loacal and 1 global minima\n",
        "# MAE: conversion takes more time"
      ],
      "metadata": {
        "id": "WyCefJ95bDqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is it more appropriate to use?"
      ],
      "metadata": {
        "id": "3mnd980DbEFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso regularization is a technique used in linear regression to prevent overfitting by adding a penalty term to the loss function that encourages the coefficients of the independent variables to be close to zero.\n",
        "# Ridge regression is use reduce overfitting of model\n",
        "# Lasso is useful for feature selection"
      ],
      "metadata": {
        "id": "BVuWD9KobHNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an example to illustrate."
      ],
      "metadata": {
        "id": "2zqUsAvBbHi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularized linear models, such as Lasso and Ridge regression, help prevent overfitting in machine learning by adding a penalty term to the loss function that encourages the model to have smaller and simpler coefficients. \n",
        "# For example, suppose we have a dataset with many features most of them not very important and if we trained our data on this noisy dataset it may overfit, to overcome this problem we use regularization."
      ],
      "metadata": {
        "id": "4-_kSFzIbK9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best choice for regression analysis."
      ],
      "metadata": {
        "id": "6qcWy9x2bLhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# regularized linear models assume that the relationship between the independent and dependent variables is linear. \n",
        "# regularized linear models require careful selection of the regularization hyperparameters, such as the regularization strength. Choosing appropriate values for these hyperparameters can be challenging\n",
        "# regularized linear models can be computationally expensive, particularly when the number of features is very large\n",
        "# regularized linear models can be less interpretable than other models that do not use regularization. "
      ],
      "metadata": {
        "id": "EoU-IPZwbO9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
        "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
        "performer, and why? Are there any limitations to your choice of metric?"
      ],
      "metadata": {
        "id": "ke3metpMbPQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If the goal is to minimize the absolute magnitude of errors, then Model B would be the better choice since it has a lower MAE. However, if the goal is to minimize the squared magnitude of errors, then Model A would be the better choice since it has a lower RMSE."
      ],
      "metadata": {
        "id": "Zgbd-b89bS6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. You are comparing the performance of two regularized linear models using different types of\n",
        "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
        "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
        "better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
        "method?"
      ],
      "metadata": {
        "id": "FJXyWMSgbUdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If the goal is to produce a simpler and more interpretable model, then Model B may be the better choice since it has a higher likelihood of setting some coefficients to zero. On the other hand, if the goal is to balance simplicity with accuracy, then Model A may be the better choice since it does not set any coefficients exactly to zero."
      ],
      "metadata": {
        "id": "5hVAVlyubWi6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}